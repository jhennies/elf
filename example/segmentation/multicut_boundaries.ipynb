{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multicut\n",
    "\n",
    "Use the `elf.segmentation` module for boundary based multicut segmentation: [Multicut brings automated neurite segmentation closer to human performance](https://www.nature.com/articles/nmeth.4151). We use data from the [ISBI 2012 EM Segmentation challenge](http://brainiac2.mit.edu/isbi_challenge/home) and [The Mutex Watershed: Efficent, Parameter-Free Image Partitionong](http://openaccess.thecvf.com/content_ECCV_2018/html/Steffen_Wolf_The_Mutex_Watershed_ECCV_2018_paper.html).\n",
    "You can obtain the example data [here](https://hcicloud.iwr.uni-heidelberg.de/index.php/s/6LuE7nxBN3EFRtL).\n",
    "\n",
    "The boundary based segmentation approach works as follows:\n",
    "1. Predict pixel-wise affinity (or boundary) map. Here, we use pre-computed results for this step.\n",
    "2. Compute a watershed over-segmentation based on the affinity maps.\n",
    "3. Compute the region adjacency graph defined by the watershed over-segmentation.\n",
    "4. Compute weights for the edges of this graph by accumulating the affinity (or boundary) map over the edge pixels.\n",
    "5. Partition the graph based on the edge weights via Multicut and project the result back to the pixel level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/kreshuk/pape/Work/software/src/napari/napari/__init__.py:27: UserWarning: \n",
      "    napari was tested with QT library `>=5.12.3`.\n",
      "    The version installed is 5.9.6. Please report any issues with this\n",
      "    specific QT version at https://github.com/Napari/napari/issues.\n",
      "    \n",
      "  warn(message=warn_message)\n"
     ]
    }
   ],
   "source": [
    "%gui qt5 \n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "# import napari for data visualisation\n",
    "import napari\n",
    "\n",
    "# import the segmentation functionality from elf\n",
    "import elf.segmentation.multicut as mc\n",
    "import elf.segmentation.features as feats\n",
    "import elf.segmentation.watershed as ws\n",
    "from elf.segmentation.utils import seg_to_edges\n",
    "\n",
    "# import the open_file function from elf, which supports opening files\n",
    "# in hdf5, zarr, n5 or knossos file format\n",
    "from elf.io import open_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "# you can download the example data from here:\n",
    "# https://hcicloud.iwr.uni-heidelberg.de/index.php/s/6LuE7nxBN3EFRtL\n",
    "data_path = '/home/pape/Work/data/isbi/isbi_test_volume.h5'  # adjust this path\n",
    "with open_file(data_path, 'r') as f:\n",
    "    # load the raw data\n",
    "    raw = f['raw'][:]\n",
    "pmap_path = '/home/pape/Work/data/isbi/fabian/isbi_test_prob.tif'\n",
    "pmaps = 1. - np.asarray(imageio.volread(pmap_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.9999947\n"
     ]
    }
   ],
   "source": [
    "print(pmaps.min(), pmaps.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'probabilities' at 0x7fa45f3a2978>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize the raw data and the affinity maps with napari\n",
    "# TODO switch to new napari syntax\n",
    "# napari.view_image(raw, name='raw')\n",
    "# napari.view_image(affs, name='affinities')\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(raw, name='raw')\n",
    "viewer.add_image(pmaps, name='probabilities')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the Multicut problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute watershed over-segmentation based on the probability maps\n",
    "\n",
    "\n",
    "# next, we run the distance transform watershed.\n",
    "# the data is very anisotropic, so we apply the watershed in 2d\n",
    "# and stack the watershed results along z, with the appropriate id offset\n",
    "watershed = np.zeros_like(raw, dtype='uint64')\n",
    "offset = 0\n",
    "for z in range(watershed.shape[0]):\n",
    "    # the threshold parameter determines at which value the input map is thresholded before applying\n",
    "    # the distance transform.\n",
    "    # the parameter sigma_seeds determines how strong the seed map is smoothed before seeds are\n",
    "    # computed via local minima. This controls the degree of over-segmentation\n",
    "    wsz, max_id = ws.distance_transform_watershed(pmaps[z], threshold=.5, sigma_seeds=2.)\n",
    "    wsz += offset\n",
    "    offset += max_id\n",
    "    watershed[z] = wsz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'watershed' at 0x7fd670388a90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize the watershed result\n",
    "# TODO switch to new napari syntax\n",
    "# napari.view_image(raw, name='raw')\n",
    "# napari.add_labels(watershed, name='watershed')\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(raw, name='raw')\n",
    "viewer.add_labels(watershed, name='watershed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77466.0\n",
      "-0.028835723 3.0622032\n",
      "494.0\n",
      "-4.4614334 3.3327825\n"
     ]
    }
   ],
   "source": [
    "# compute the region adjacency graph\n",
    "rag = feats.compute_rag(watershed)\n",
    "\n",
    "# compute the edge costs\n",
    "costs = feats.compute_boundary_features(rag, pmaps)[:, 0]\n",
    "\n",
    "# transform the edge costs from [0, 1] to  [-inf, inf], which is\n",
    "# necessary for the multicut. This is done by intepreting the values\n",
    "# as probabilities for an edge being 'true' and then taking the negative log-likelihood.\n",
    "\n",
    "# in addition, we weight the costs by the size of the corresponding edge\n",
    "# for z and xy edges\n",
    "z_edges = feats.compute_z_edge_mask(rag, watershed)\n",
    "xy_edges = np.logical_not(z_edges)\n",
    "edge_populations = [z_edges, xy_edges]\n",
    "edge_sizes = feats.compute_boundary_mean_and_length(rag, pmaps)[:, 1]\n",
    "costs = mc.transform_probabilities_to_costs(costs, edge_sizes=edge_sizes,\n",
    "                                            edge_populations=edge_populations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.4614334\n",
      "3.3327825\n"
     ]
    }
   ],
   "source": [
    "print(costs.min())\n",
    "print(costs.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve the Multicut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the multicut partitioning, here, we use the kernighan lin \n",
    "# heuristics to solve the problem, introduced in\n",
    "# http://xilinx.asia/_hdl/4/eda.ee.ucla.edu/EE201A-04Spring/kl.pdf\n",
    "node_labels = mc.multicut_kernighan_lin(rag, costs)\n",
    "\n",
    "# map the results back to pixels to obtain the final segmentation\n",
    "segmentation = feats.project_node_labels_to_pixels(rag, node_labels)\n",
    "edges = 1. - seg_to_edges(segmentation, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'edge_volume' at 0x7fd668912fd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize the segmentation result\n",
    "# TODO switch to new napari syntax\n",
    "# napari.view_image(raw, name='raw')\n",
    "# napari.add_labels(segmentation, name='multicut-segmentation')\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(raw, name='raw')\n",
    "viewer.add_image(pmaps, name='boundaries')\n",
    "viewer.add_labels(segmentation, name='multicut')\n",
    "viewer.add_image(edges.astype('float32'), name='edge_volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: QXcbConnection: XCB error: 148 (Unknown), sequence: 5256, resource id: 0, major code: 140 (Unknown), minor code: 20\n",
      "WARNING: QXcbConnection: XCB error: 148 (Unknown), sequence: 5263, resource id: 0, major code: 140 (Unknown), minor code: 20\n"
     ]
    }
   ],
   "source": [
    "imageio.volwrite('mc-result-segmentation.tif', segmentation)\n",
    "imageio.volwrite('mc-result-edges.tif', edges.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
